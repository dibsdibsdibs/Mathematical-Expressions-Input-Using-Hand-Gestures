{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8-FHwBoSR5v"
      },
      "source": [
        "#Computer Vision Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5pfZQBwSWMm"
      },
      "source": [
        "Details:\n",
        "*   Sign Language Dataset for ASL Numbers and Operators\n",
        "*   CNN for recognizing hand sign\n",
        "*   OpenCV to capture hand gestures\n",
        "*   use trained model to recognize hand gestures\n",
        "*   recognized signs to form mathematical expression\n",
        "*   evaluate expression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzSkJWwmSaUo",
        "outputId": "f5d4b59d-d5c4-4c61-faa5-b682dc358a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.4)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.7)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: protobuf, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.14 protobuf-4.25.3 sounddevice-0.4.6\n",
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.10/dist-packages (from PyDrive) (2.84.0)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.10/dist-packages (from PyDrive) (6.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (4.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.9)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive) (1.63.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive) (4.25.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.2->PyDrive) (5.3.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client>=1.2->PyDrive) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets\n",
        "!pip install pandas\n",
        "!pip install opencv-python\n",
        "!pip install mediapipe\n",
        "!pip install PyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JzUZOqwv3gdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc6c03e-63d0-4b6c-bdb6-2e3aba810516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ],
      "source": [
        "import opendatasets as od\n",
        "import pandas\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import requests\n",
        "import pandas as pd\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Bx_zHpTyberu"
      },
      "outputs": [],
      "source": [
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsILoqdsz5Ke",
        "outputId": "60d79f0b-f8d2-4be4-e303-0186845a69b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: divinelavente\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/divinelavente/american-sign-language-digit-dataset\n",
            "Downloading american-sign-language-digit-dataset.zip to ./american-sign-language-digit-dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 128M/128M [00:05<00:00, 26.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/divinelavente/american-sign-language-digit-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0tEcfyMFxRy4"
      },
      "outputs": [],
      "source": [
        "# import shutil\n",
        "# directory_to_delete = '/content/'\n",
        "# shutil.rmtree(directory_to_delete)\n",
        "# print(\"Dataset deleted successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By656OgTUlm5",
        "outputId": "75de1f05-6030-454d-c58a-aa95d27ec37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Contents of the current directory: ['.config', 'american-sign-language-digit-dataset', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "print(\"Current working directory:\", os.getcwd())\n",
        "\n",
        "print(\"Contents of the current directory:\", os.listdir())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/american-sign-language-digit-dataset/American Sign Language Digits Dataset\""
      ],
      "metadata": {
        "id": "j25Fpn-PtOSf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VkZF_gLdlljP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54248813-8de4-4d98-9357-7da68ede1b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Contents of the current directory: ['.config', 'american-sign-language-digit-dataset', 'sample_data']\n",
            "Directory '.config' is not empty. Contains: ['logs', 'config_sentinel', '.last_survey_prompt.yaml', 'default_configs.db', 'configurations', '.last_opt_in_prompt.yaml', '.last_update_check.json', 'gce', 'active_config']\n",
            "Directory 'american-sign-language-digit-dataset' is not empty. Contains: ['American Sign Language Digits Dataset']\n",
            "Directory 'sample_data' is not empty. Contains: ['README.md', 'anscombe.json', 'california_housing_train.csv', 'california_housing_test.csv', 'mnist_test.csv', 'mnist_train_small.csv']\n"
          ]
        }
      ],
      "source": [
        "current_directory = os.getcwd()\n",
        "print(f\"Current working directory: {current_directory}\")\n",
        "\n",
        "contents = os.listdir(current_directory)\n",
        "print(f\"Contents of the current directory: {contents}\")\n",
        "\n",
        "for item in contents:\n",
        "    item_path = os.path.join(current_directory, item)\n",
        "    if os.path.isdir(item_path):\n",
        "        sub_contents = os.listdir(item_path)\n",
        "        if sub_contents:\n",
        "            print(f\"Directory '{item}' is not empty. Contains: {sub_contents}\")\n",
        "        else:\n",
        "            print(f\"Directory '{item}' is empty.\")\n",
        "    else:\n",
        "        print(f\"'{item}' is not a directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "a4vb_rRaJU1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64e1588-95f1-453e-b9a9-15dd7a7ef951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keypoints extracted:  4391\n",
            "Labels extracted:  4391\n"
          ]
        }
      ],
      "source": [
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.7)\n",
        "\n",
        "def extract_keypoints(image):\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    result = hands.process(image_rgb)\n",
        "    if result.multi_hand_landmarks:\n",
        "        hand_landmarks = result.multi_hand_landmarks[0]\n",
        "        keypoints = []\n",
        "        for lm in hand_landmarks.landmark:\n",
        "            keypoints.extend([lm.x, lm.y, lm.z])\n",
        "        return keypoints\n",
        "    return None\n",
        "\n",
        "imagepaths = []\n",
        "for root, dirs, files in os.walk(base_path):\n",
        "    for file in files:\n",
        "        if file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            imagepaths.append(os.path.join(root, file))\n",
        "\n",
        "X = []  # keypoints\n",
        "y = []  # labels\n",
        "\n",
        "for path in imagepaths:\n",
        "    img = cv2.imread(path)\n",
        "    if img is None:\n",
        "        print(f\"Error: The image at path '{path}' could not be read.\")\n",
        "        continue\n",
        "    keypoints = extract_keypoints(img)\n",
        "    if keypoints:\n",
        "        X.append(keypoints)\n",
        "        try:\n",
        "            folder_name = path.split(\"/\")[-2]\n",
        "            label = ''.join(filter(str.isdigit, folder_name))\n",
        "            y.append(int(label))\n",
        "        except ValueError as ve:\n",
        "            print(f\"Error: Unable to convert label to integer in path '{path}': {ve}\")\n",
        "            continue\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Keypoints extracted: \", len(X))\n",
        "print(\"Labels extracted: \", len(y))\n",
        "\n",
        "# save keypoints and labels for training\n",
        "np.save('X_keypoints.npy', X)\n",
        "np.save('y_labels.npy', y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout"
      ],
      "metadata": {
        "id": "jxYfRO1iOHvM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZTD6WChtpQZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f53600-89dc-42d4-cf06-c4ae9d749d4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_keypoints shape: (4391, 63)\n",
            "y_labels shape: (4391,)\n",
            "Epoch 1/30\n",
            "110/110 [==============================] - 2s 5ms/step - loss: 2.5821 - accuracy: 0.1384 - val_loss: 2.2194 - val_accuracy: 0.3868\n",
            "Epoch 2/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 2.0792 - accuracy: 0.3138 - val_loss: 1.6268 - val_accuracy: 0.7213\n",
            "Epoch 3/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.5568 - accuracy: 0.5074 - val_loss: 1.0582 - val_accuracy: 0.8237\n",
            "Epoch 4/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.1507 - accuracy: 0.6577 - val_loss: 0.7007 - val_accuracy: 0.9101\n",
            "Epoch 5/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.8738 - accuracy: 0.7395 - val_loss: 0.4850 - val_accuracy: 0.9306\n",
            "Epoch 6/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.7930 - val_loss: 0.3366 - val_accuracy: 0.9386\n",
            "Epoch 7/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.8423 - val_loss: 0.2551 - val_accuracy: 0.9750\n",
            "Epoch 8/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8554 - val_loss: 0.1921 - val_accuracy: 0.9795\n",
            "Epoch 9/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8921 - val_loss: 0.1452 - val_accuracy: 0.9886\n",
            "Epoch 10/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3754 - accuracy: 0.8927 - val_loss: 0.1202 - val_accuracy: 0.9852\n",
            "Epoch 11/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3218 - accuracy: 0.9092 - val_loss: 0.1076 - val_accuracy: 0.9829\n",
            "Epoch 12/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.9203 - val_loss: 0.0866 - val_accuracy: 0.9875\n",
            "Epoch 13/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.9305 - val_loss: 0.0756 - val_accuracy: 0.9898\n",
            "Epoch 14/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2371 - accuracy: 0.9331 - val_loss: 0.0616 - val_accuracy: 0.9886\n",
            "Epoch 15/30\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.9431 - val_loss: 0.0564 - val_accuracy: 0.9886\n",
            "Epoch 16/30\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.1942 - accuracy: 0.9479 - val_loss: 0.0539 - val_accuracy: 0.9920\n",
            "Epoch 17/30\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.1893 - accuracy: 0.9519 - val_loss: 0.0520 - val_accuracy: 0.9920\n",
            "Epoch 18/30\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.1787 - accuracy: 0.9473 - val_loss: 0.0464 - val_accuracy: 0.9920\n",
            "Epoch 19/30\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.1649 - accuracy: 0.9556 - val_loss: 0.0436 - val_accuracy: 0.9920\n",
            "Epoch 20/30\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.1666 - accuracy: 0.9593 - val_loss: 0.0466 - val_accuracy: 0.9909\n",
            "Epoch 21/30\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.1518 - accuracy: 0.9604 - val_loss: 0.0412 - val_accuracy: 0.9932\n",
            "Epoch 22/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9604 - val_loss: 0.0406 - val_accuracy: 0.9932\n",
            "Epoch 23/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9658 - val_loss: 0.0410 - val_accuracy: 0.9920\n",
            "Epoch 24/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1284 - accuracy: 0.9673 - val_loss: 0.0395 - val_accuracy: 0.9920\n",
            "Epoch 25/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1307 - accuracy: 0.9647 - val_loss: 0.0411 - val_accuracy: 0.9920\n",
            "Epoch 26/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1284 - accuracy: 0.9636 - val_loss: 0.0372 - val_accuracy: 0.9920\n",
            "Epoch 27/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1192 - accuracy: 0.9698 - val_loss: 0.0357 - val_accuracy: 0.9920\n",
            "Epoch 28/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9698 - val_loss: 0.0348 - val_accuracy: 0.9920\n",
            "Epoch 29/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1114 - accuracy: 0.9721 - val_loss: 0.0338 - val_accuracy: 0.9932\n",
            "Epoch 30/30\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1135 - accuracy: 0.9712 - val_loss: 0.0352 - val_accuracy: 0.9932\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9932\n",
            "Test accuracy: 0.9931740760803223\n"
          ]
        }
      ],
      "source": [
        "X_keypoints = np.load('X_keypoints.npy')\n",
        "y_labels = np.load('y_labels.npy')\n",
        "print(f\"X_keypoints shape: {X_keypoints.shape}\")\n",
        "print(f\"y_labels shape: {y_labels.shape}\")\n",
        "\n",
        "y_labels = y_labels.astype(int)\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_keypoints, y_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# cnn model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_keypoints.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(17, activation='softmax')  # 10 classes for digits 0-9\n",
        "])\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train model\n",
        "model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))\n",
        "\n",
        "# eval model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pZZgOHpfuts0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "fbf94f57-ece0-4e9c-acc5-40ee251e474c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-451c0da75a47>:4: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  save_model(model, 'hand_gesture_model.h5')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8621f011-6ddb-4e09-9c74-ec3e352bbfb1\", \"hand_gesture_model.h5\", 245504)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.models import save_model\n",
        "from google.colab import files\n",
        "\n",
        "save_model(model, 'hand_gesture_model.h5')\n",
        "files.download('hand_gesture_model.h5')\n",
        "\n",
        "# save h5 for app"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base_path = \"/content/american-sign-language-digit-dataset/American Sign Language Digits Dataset/*\""
      ],
      "metadata": {
        "id": "LKZh6PAu2GlX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mp_hands = mp.solutions.hands\n",
        "# hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "# # Function to visualize keypoints on the image\n",
        "# def visualize_keypoints(image, hand_landmarks):\n",
        "#     if hand_landmarks:\n",
        "#         for hand_landmark in hand_landmarks:\n",
        "#             for lm in hand_landmark.landmark:\n",
        "#                 x, y = int(lm.x * image.shape[1]), int(lm.y * image.shape[0])\n",
        "#                 cv2.circle(image, (x, y), 5, (0, 255, 0), -1)\n",
        "#     return image\n",
        "\n",
        "# # Function to extract keypoints from an image\n",
        "# def extract_keypoints(image):\n",
        "#     image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#     result = hands.process(image_rgb)\n",
        "#     if result.multi_hand_landmarks:\n",
        "#         return result.multi_hand_landmarks\n",
        "#     return None\n",
        "\n",
        "# # Get list of image paths\n",
        "# imagepaths = []\n",
        "# for root, dirs, files in os.walk(base_path):\n",
        "#     for file in files:\n",
        "#         if file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "#             imagepaths.append(os.path.join(root, file))\n",
        "\n",
        "# # Loop through each image, extract keypoints, and display the image with keypoints drawn\n",
        "# for path in imagepaths:\n",
        "#     img = cv2.imread(path)\n",
        "#     if img is None:\n",
        "#         print(f\"Error: The image at path '{path}' could not be read.\")\n",
        "#         continue\n",
        "#     hand_landmarks = extract_keypoints(img)\n",
        "#     if hand_landmarks:\n",
        "#         img_with_keypoints = visualize_keypoints(img.copy(), hand_landmarks)\n",
        "#         plt.imshow(cv2.cvtColor(img_with_keypoints, cv2.COLOR_BGR2RGB))\n",
        "#         plt.axis('off')\n",
        "#         plt.show()"
      ],
      "metadata": {
        "id": "yRTgyN8Vxl1K"
      },
      "execution_count": 16,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}